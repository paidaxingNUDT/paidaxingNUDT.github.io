[{"title":"LeetCode题目记录及心得","url":"/2019/03/01/LeetCode题目记录及心得/","content":"\n# {LeetCode题目记录及心得}\n\n之前没做过这类题目，只参加过蓝桥杯，也没有名次，大学对算法也没学好。。只能恶补\n\n## [992. K 个不同整数的子数组](https://leetcode-cn.com/problems/subarrays-with-k-different-integers/)\n\n难度：困难\n\n对于浅显的解来说，三重循环，超出时间限制\n\n    class Solution:\n        def subarraysWithKDistinct(self, A: List[int], K: int) -> int:\n            \"得到A的不同的子数组，子数组长度在k-len(A)\"    \n            total_num = 0\n            for sub_len in range(K,len(A)+1):\n                \"当子数组长度为sub_len时\"\n                for i in range(len(A)-sub_len+1):\n                    sub_list = A[i:sub_len+i]\n                    if self.cal_differ_num(sub_list)==K:\n                        total_num += 1\n            return total_num\n            \n    def cal_differ_num(self,A):\n        \"返回A中不同整数的个数\"\n        list_num = []\n        differ_num = 0\n        for i in A:\n            if i in list_num:\n                continue\n            else:\n                list_num.append(i)\n                differ_num +=1\n        return differ_num"},{"title":"pytorch迁移学习中parameters requires_grad=False和optimizer优化参数的探讨","url":"/2019/02/27/pytorch迁移学习中parameters-requires-grad-False和optimizer优化参数的探讨/","content":"\n# pytorch迁移学习中parameters requires_grad=False和optimizer优化参数的探讨\n\n首先，背景是迁移学习，将已经预训练好的DeepLabV3+参数迁移到前背景分割任务中。固定特征提取层，更改之后的decoder层。\n\n有一段代码感到疑惑：\n\n```python\nfor param in vgg.features.parameters():\n\tparam.requeires_grad=False\n#定义优化器时\noptimizer=optim.SGD(vgg.classifier.paramters(),lr=0.001)\n```\n\n首先第一句代码的作用是：特征层中参数都固定住，不会发生梯度的更新；第二句代码的作用是定义一个优化器，这个优化器的作用是优化全连接层中的参数，并没有说要优化特征层中的参数。为什么两个代码要一起用呢？下面的优化器参数是网络所有参数运行起来会有什么变化吗？或者去掉上面的代码，理应也是可以正常运行的，因为并没有要改变特征层的参数。\n\n\n\n因此我做了一些实验验证了自己的想法。\n\n只写第一句那么，特征层不会产生梯度，但是梯度会在其中传播。也就是说如果，你对第二层限制求梯度，那么第二层不会产生改变量（梯度*学习率），但是第一层会产生梯度，也可以进行改变。\n\n只写第二句，梯度正常产生，但是由于优化器没有涉及特征层的参数，所以特征层虽然产生了梯度，但是参数却不会改变。\n\n由一位网友的提示，required_grad这一句是确定是否计算导数的。所以有第一句可以减少计算量，也就是不用求w和b的导数了，减少了计算量。只传播误差，而不计算权重和偏执的导数。\n\n{% asset_img 20180613131226.png This is an example image %}","tags":["认真学习的猴赛雷"]},{"title":"pytorch分割论文写作记录","url":"/2019/01/23/pytorch分割论文写作记录/","content":"\n# 分割论文写作记录\n\n## 2019图像会议整理\n\n以下是整理的2019近期（1.23日）的会议信息。\n\n![2019图像会议整理](C:\\Users\\Monkey\\Pictures\\博客配图\\论文投稿\\2019图像会议整理.png)\n\n\n\n","tags":["认真学习的猴赛雷"]},{"title":"python-opencv 截取图像一部分","url":"/2019/01/21/python-opencv-截取图像一部分/","content":"\n# python-opencv 截取图像一部分\n\n截取图像中心，且截取过之后的图像为正方形\n\n```\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Mon Jan 21 18:05:23 2019\n\n@author: Monkey\n\"\"\"\n\nimport cv2\nimport os\n\nroot_path = r'E:\\aircraft_data\\aircraft\\aircraft_adjust'\nfiles = os.listdir(root_path)\nfor file in files:\n    path = os.path.join(root_path,file)\n    images = os.listdir(path)\n    for imagename in images:\n        imagepath = os.path.join(path,imagename)\n        img = cv2.imread(imagepath)\n        sp = img.shape\n        sz1 = sp[0]                 #图像的高度（行 范围）\n        sz2 = sp[1]                 #图像的宽度（列 范围）\n        \n        if sz1>sz2:\n            maxx = sz1\n            minx = sz2\n        else:\n            maxx = sz2\n            minx = sz1\n        \n        index = int(minx/2)-10\n        center = (int(sz1/2),int(sz2/2))\n        a = center[0] - index\n        b = center[0] + index\n        c = center[1] - index\n        d = center[1] + index\n        \n        imgcrop = img[a:b,c:d]\n        cv2.imwrite('test.jpg',imgcrop)\n        \n```\n\n图像路径名有中文是opencv是读取不了图片的，所以我还加了一个重命名的过程\n\n```\ndef renameallname(root_path):\n    files = os.listdir(root_path)\n    for file in files:\n        path = os.path.join(root_path,file)\n        images = os.listdir(path)\n        name = 1\n        for imagename in images:\n            imagepath = os.path.join(path,imagename)\n            print(imagepath)\n            dstname = os.path.join(path,str(name)+'.jpg')\n            os.rename(imagepath,dstname)\n            name += 1\n```\n\n\n\n"},{"title":"github desktop 使用命令记录","url":"/2019/01/11/github-desktop-使用命令记录/","content":"\n# github desktop 使用命令记录\n\n# 删除histoty 记录\n\nGithub Git彻底删除历史提交记录的方法\n\n在文件夹目录下右键-> git bush here ，输入\n\n```\ngit reset --hard HEAD^ \n```\n\n查看desktop就能发现最上面一条history没有了。\n\n\n\n"},{"title":"从头学习图像细分类网络详细记录","url":"/2019/01/09/从头学习分类网络详细记录/","content":"\n# 从头学习图像细分类网络详细记录\n\n##  写代码前期准备：\n\n###  code\n\n[VGG-TensorFlow代码链接：](https://github.com/machrisaa/tensorflow-vgg)\n\n为什么选择该代码，原因如下：\n\n① 基本的网络结构有，简单测试也有，可以大规模修改\n\n② issue提交较多，有什么问题大家都遇到过，可以参考\n\n③ 基于之前的分割网络，再使用细分类网络【这一点想到是否可以利用之前的分割网络来进行分类？我是小白。。没读多少文章】；分割网络有详细的dataset如何组织，loss如何计算等可以参考\n\n④ 还是自己想学着搭建一点\n\n这篇文章可能会持续很久\n\n### pre-trained模型\n\n之前训练过VGG网络用来进行图像分割，下载了一个vgg16.npz模型，了解了一下差别：\n\nnpy和npz文件，都是numpy存储保存数据的格式。\n\nnpy文件是通过np.save和np.load来进行读写的，存储到磁盘上是未压缩的原始的二进制格式。\n\n而npz格式可以通过np.savez将多个数组保存到一个文件中，输出的是一个压缩文件npz，可以使用rar打开查看，其中每个文件都是npy格式。\n\n下载的[vgg16.npy](https://pan.baidu.com/s/1weg_hw-F9wVjK0J7ldjNZw)，是在学习该博主的使用[tensorflow搭建迁移学习](https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/5-16-transfer-learning/)的网络中保存在他的百度云账号中。\n\n另外还有参考[csdn博客](https://blog.csdn.net/weixin_31200719/article/details/81220924)\n\n预训练模型下载完毕，有一点疑问？\n\n我使用这个在1000类上的分类网络参数，想要这个网络通过微调能够进行其中某一类的细分类，是否能够完成？\n\n先粗略的实验吧，看看效果。\n\n## 修改vgg16模型代码：\n\n![5_16_04](http://pl06226jn.bkt.clouddn.com/%E7%BD%91%E7%BB%9C%E7%BB%86%E5%88%86%E7%B1%BB%E5%8D%9A%E5%AE%A25_16_04.png)\n\n\n\n首先了解一下vgg16的参数：\n\n```python\nINPUT: [224x224x3]        memory:  224*224*3=150K   weights: 0\nCONV3-64: [224x224x64]  memory:  224*224*64=3.2M   weights: (3*3*3)*64 = 1,728\nCONV3-64: [224x224x64]  memory:  224*224*64=3.2M   weights: (3*3*64)*64 = 36,864\nPOOL2: [112x112x64]  memory:  112*112*64=800K   weights: 0\nCONV3-128: [112x112x128]  memory:  112*112*128=1.6M   weights: (3*3*64)*128 = 73,728\nCONV3-128: [112x112x128]  memory:  112*112*128=1.6M   weights: (3*3*128)*128 = 147,456\nPOOL2: [56x56x128]  memory:  56*56*128=400K   weights: 0\nCONV3-256: [56x56x256]  memory:  56*56*256=800K   weights: (3*3*128)*256 = 294,912\nCONV3-256: [56x56x256]  memory:  56*56*256=800K   weights: (3*3*256)*256 = 589,824\nCONV3-256: [56x56x256]  memory:  56*56*256=800K   weights: (3*3*256)*256 = 589,824\nPOOL2: [28x28x256]  memory:  28*28*256=200K   weights: 0\nCONV3-512: [28x28x512]  memory:  28*28*512=400K   weights: (3*3*256)*512 = 1,179,648\nCONV3-512: [28x28x512]  memory:  28*28*512=400K   weights: (3*3*512)*512 = 2,359,296\nCONV3-512: [28x28x512]  memory:  28*28*512=400K   weights: (3*3*512)*512 = 2,359,296\nPOOL2: [14x14x512]  memory:  14*14*512=100K   weights: 0\nCONV3-512: [14x14x512]  memory:  14*14*512=100K   weights: (3*3*512)*512 = 2,359,296\nCONV3-512: [14x14x512]  memory:  14*14*512=100K   weights: (3*3*512)*512 = 2,359,296\nCONV3-512: [14x14x512]  memory:  14*14*512=100K   weights: (3*3*512)*512 = 2,359,296\nPOOL2: [7x7x512]  memory:  7*7*512=25K  weights: 0\nFC: [1x1x4096]  memory:  4096  weights: 7*7*512*4096 = 102,760,448\nFC: [1x1x4096]  memory:  4096  weights: 4096*4096 = 16,777,216\nFC: [1x1x1000]  memory:  1000 weights: 4096*1000 = 4,096,000\n \nTOTAL memory: 24M * 4 bytes ~= 93MB / image (only forward! ~*2 for bwd)\nTOTAL params: 138M parameters\n\n```\n\n我能够理解卷积层的作用：通过卷积核，使得下一层与上一层有联系，并且保证了提取局部特征。\n\npooling 层最大的作用是引入不变性，例如max_pooling取一片区域的最大值，所以这个最大值在该区域内无论在哪，max-pooling之后都是它，相当于对微小位移的不变性。并且能够提升计算速度，大部分不重要的细节都被省略。\n\n卷积层、池化层和激活函数层等操作是将原始数据映射到隐层特征空间\n\n全连接层在整个卷积神经网络中起到“分类器”的作用。将学习到的分布式特征映射到样本标记空间的作用。\n\n激活函数：将神经网络每层输出结果变得非线性化？？ 常用函数 sigmoid tanh relu\n\n> 全连接层可由卷积操作实现：对前层是全连接的全连接层可以转化为卷积核为1x1的卷积；而前层是卷积层的全连接层可以转化为卷积核为hxw的全局卷积，h和w分别为前层卷积结果的高和宽\n>\n> [来源知乎，引用地址](https://www.zhihu.com/question/41037974/answer/150522307)\n\n正则化：防止过拟合，在神经网路中通过在反向传播误差更新权值时候随机选择一部分权值不更新，相当于随机删除一部分hidden units（不是真实删除了，只是暂时不使用这部分units），通过这样的方法就能防止过拟合。\n\n```python\nclass Vgg16:\n    def build():\n        # ...前面的层\n        self.pool5 = self.max_pool(self.conv5_3, 'pool5')\n```\n\n根据莫烦python所说，在这个vgg16，pooling5之前的层，都是不能被 train 的，OK那我们不动. \n\npool5 是最后的 conv 出来的结果，因为训练自己的数据，全连接层最好不要使用预训练参数。然后按照vgg19_trainable.进行修改vgg16.\n\n代码和在代码中注释修改提交至：____________________________\n\n那我们在这之后做出修改，我们只有25类，在最后我又加入一层新的全连接层，1000->25类\n\n```python\nself.fc7 = self.fc_layer(self.relu6, 4096, 4096, \"fc7\")\n        self.relu7 = tf.nn.relu(self.fc7)\n        if train_mode is not None:\n            self.relu7 = tf.cond(train_mode, lambda: tf.nn.dropout(self.relu7, self.dropout), lambda: self.relu7)\n        elif self.trainable:\n            self.relu7 = tf.nn.dropout(self.relu7, self.dropout)\n\n        self.fc8 = self.fc_layer(self.relu7, 4096, 1000, \"fc8\")\n\n        self.prob = tf.nn.softmax(self.fc8, name=\"prob\")\n```\n\n先按照之前的测试用例来看，是否能通过两张图的非训练状态。噢噢出现错误了，赶紧记录下来：\n\n```\nTraceback (most recent call last):\n  File \"D:\\project\\tensorflow-vgg-master\\test_vgg16.py\", line 30, in <module>\n    prob = sess.run(vgg.prob, feed_dict=feed_dict)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 895, in run\n    run_metadata_ptr)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1128, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1344, in _do_run\n    options, run_metadata)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1363, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value conv1_2/conv1_2_biases\n         [[Node: conv1_2/conv1_2_biases/read = Identity[T=DT_FLOAT, _class=[\"loc:@conv1_2/conv1_2_biases\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv1_2/conv1_2_biases)]]\n\nCaused by op 'conv1_2/conv1_2_biases/read', defined at:\n  File \"D:\\project\\tensorflow-vgg-master\\test_vgg16.py\", line 25, in <module>\n    vgg.build(images,train_mode)\n  File \"D:\\project\\tensorflow-vgg-master\\vgg16.py\", line 48, in build\n    self.conv1_2 = self.conv_layer(self.conv1_1, 64 , 64 , \"conv1_2\")\n  File \"D:\\project\\tensorflow-vgg-master\\vgg16.py\", line 117, in conv_layer\n    filt, conv_biases = self.get_conv_var(3, in_channels, out_channels, name)\n  File \"D:\\project\\tensorflow-vgg-master\\vgg16.py\", line 135, in get_conv_var\n    biases = self.get_var(initial_value, name, 1, name + \"_biases\")\n  File \"D:\\project\\tensorflow-vgg-master\\vgg16.py\", line 147, in get_var\n    var = tf.Variable(value, name=var_name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 229, in __init__\n    constraint=constraint)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 376, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 127, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 2728, in identity\n    \"Identity\", input=input, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value conv1_2/conv1_2_biases\n         [[Node: conv1_2/conv1_2_biases/read = Identity[T=DT_FLOAT, _class=[\"loc:@conv1_2/conv1_2_biases\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv1_2/conv1_2_biases)]]\n```\n\n这么长是说，在run这个语句：\n\n```\nprob = sess.run(vgg.prob, feed_dict=feed_dict)\n```\n\n的时候，有没有初始化的变量。\n\n我们在run之前加一句\n\n```\nsess.run(tf.global_variables_initializer())\n```\n\n完美解决。\n\n以上是修改过的网络，通过简单两张图的测试的过程。\n\n\n\n## 修改vgg训练代码\n\n### 数据前期准备和读取\n\n要完成微调，首先得写一下loss，写loss前，首先得把数据的标签one-hot类型的给写了，因为我的只有25类，而且数据文件夹的格式是这样的:\n\n```\n-data\n|\n|---0\n|\t|\n|\t-----xxx.bmp\n|\t-----xxx.bmp\n|---1\n.....\n```\n\n所以写了一段代码将文件的路径和label数据都存入txt，需要的时候直接读取，并转换成onehot数据即可。在module1.py中，主要代码：\n\n```\n\"\"\"\n将图像路径和label写入txt文件\nauthor:monkey\n\"\"\"\nidx = -1\nfor dirpath,dirs,files in os.walk(datapath):\n    for file in files:\n        label = labels[idx]\n        writepath = os.path.join(dirpath,file)\n        filetxt.write(writepath)\n        filetxt.write(' ')\n        filetxt.write(label)\n        filetxt.write('\\n')\n    idx += 1\n```\n\n写标签文件之后，写一个dataset的类读取batch和label的代码，实现随机读取图像为batch的功能，在dataset.py中。\n\n之后直接在train文件中调用即可：\n\n```\ndataset = Datasets.dataset('./label.txt')\nbatch,labels = dataset.getbatch(batchsize)\n```\n\n### 训练代码编写\n\n搞定数据和读取之后，就是常规的tensorflow代码的编写了，写在vgg16_train.py里。\n\n训练的结果还可以：迭代2000次后准确率不错。\n\n![附上图片](http://pl06226jn.bkt.clouddn.com/%E7%BD%91%E7%BB%9C%E7%BB%86%E5%88%86%E7%B1%BB%E5%8D%9A%E5%AE%A2%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20190116090947.png)\n\n### 测试代码的编写\n\n训练时候的数据这么好看，如何保证网络没有过拟合呢？\n\n首先如同训练数据的准备一样，准备测试数据和label。注意测试数据一定要保证没有在训练数据中出现过才能保证测试的准确性。【重要的一点！得保证测试数据和训练数据的随机性】\n\n我的训练数据和测试数据就没有保证，所以得重新划分数据并且重新训练。\n\n![捕获](http://pl06226jn.bkt.clouddn.com/%E7%BD%91%E7%BB%9C%E7%BB%86%E5%88%86%E7%B1%BB%E5%8D%9A%E5%AE%A2%E6%8D%95%E8%8E%B7.PNG)\n\n![捕获2](http://pl06226jn.bkt.clouddn.com/%E7%BD%91%E7%BB%9C%E7%BB%86%E5%88%86%E7%B1%BB%E5%8D%9A%E5%AE%A2%E6%8D%95%E8%8E%B72.PNG)\n\n重新随机划分数据集的代码在module1中，自取，有很多方便的小代码也在，可以看看。\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["认真学习的猴赛雷"]},{"title":"日常配（坏）环境的一天","url":"/2019/01/09/日常配（坏）环境的一天/","content":"\n\n# 日常配（坏）环境的一天\n![别人眼里的程序员](http://pl06226jn.bkt.clouddn.com/1547002701502.png)\n\n\n\n![实际的程序员](http://pl06226jn.bkt.clouddn.com/1547002725274.png)\n\n\n\n昨天折腾了半天的VS C++环境下的OPENCV配置，没配好我就不说了。。。\n今天想接着用python环境下的opencv，也不行了。。。\n出现该错误：\nERROR: recursion is detected during loading of \"cv2\" binary extensions.\n\n细细查看了我的环境变量后，得，昨天修改的忘记改回来了，修改成正确的环境后，又得配VS下的属性页。。得，都改回来还是不行。。那怎么办，只能看路径下的文件了。。。\n\n我的python是通过anaconda安装的，VS中设置变量如下：\n![Alt text](http://pl06226jn.bkt.clouddn.com/1547002922394.png)\n没问题，也没少啥东西，C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\下也有cv2文件，也有opencv_python-3.4.1+contrib.dist-info文件夹。。。\n\n\n问题就出在这。。。多了的cv2文件夹。。。\n我重新pip uninstall opencv-python没用，还是抱这个错，删掉cv2，删掉opencv_python-3.4.1+contrib.dist-info，然后再再重装\npip install 再重新运行代码。。好勒？？？？\n\n虽然解决了但是还是一脸懵逼。。。。\n![我恨](http://pl06226jn.bkt.clouddn.com/%E6%AD%A6%E6%9E%97%E5%A4%96%E4%BC%A0%E8%A1%A8%E6%83%85%E5%8C%85%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20181101132925.png)","tags":["配环境, 吐槽"]},{"title":"20190108是填坑并且无所事事的一天","url":"/2019/01/08/20190108是填坑并且无所事事的一天/","content":"\n# 今日搭建博客总结\n\n## aloha 主题无法正确显示表格\n\n一直以为是我的语法错误 ，原来是主题的锅，要找个好看点的主题\n\nhexo本地存储图像会发生很多问题，推荐还是用七牛云开发者平台存储图像。。目前还是只会用来存图链接。。。\n\n羞愧\n\n![欸](http://pl06226jn.bkt.clouddn.com/%E6%AD%A6%E6%9E%97%E5%A4%96%E4%BC%A0%E8%A1%A8%E6%83%85%E5%8C%85%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20180612211412.png)\n\n\n\n## windows 下 opencv3.4.5 无法正确编译\n\n找了一天的，用cmake编译了一天，还是不行，连最基本的代码也说无法包含头文件，需要重启吗？\n\n![对学术冷漠的第N天](http://pl06226jn.bkt.clouddn.com/%E6%AD%A6%E6%9E%97%E5%A4%96%E4%BC%A0%E8%A1%A8%E6%83%85%E5%8C%85%E5%86%B7%E6%BC%A0.png)\n\n为什么要干这活？是python不好用了还是VS虐你不深？\n\n好后悔！我不应该踏这个hausdorff距离的坑，还不如自己写，我错了！\n\n应该认清楚baseline不应该是这样的！baseline还不如用NIPS2017的GMS-match呢！那个效果还不错啊！\n\n接下来的奋斗目标则是：\n\n周一窦老师听过我的进展之后，有两个建议：\n1. 小论文可以在细分类部分做文章，细分类部分（基于hausdorff距离的为baseline，使用机器学习细分类的方法进行分类看是否有改进）\n2. 之后的工作在分割部分： 分割部分（在不同图片情况下雪地、乌云等使用不同的loss方法可以尝试有无改进；弱监督方法，加入人机交互，画个十字，是否分割效果会好）；\n\n今日工作，重新审视基于hausdoff————审视失败。。\n\n写于2019/1/8/21：06\n\ng该下班了。。。。。。\n\n","tags":["monkey"]},{"title":"第一个博客 搭建本博客hexo+github+aliyun","url":"/2019/01/08/第一个博客-搭建本博客hexo-github-aliyun/","content":"\n## 安装node.js for windows\n### 官网下载\n链接：[nodejs官网](https://nodejs.org/en/)\n![Alt text](http://pl06226jn.bkt.clouddn.com/1546493010533.png)\n点击上方**[downloads]**，选择Windows Installer (.msi)\n![Alt text](http://pl06226jn.bkt.clouddn.com/1546493074889.png)\n双击下载好的msi安装,选择安装路径即可。\n![Alt text](http://pl06226jn.bkt.clouddn.com/1546493198850.png)\n我选择的是【node.js runtime】\n[新版本都不需要设计环境变量了，软件会自动写入环境变量]\n\n## 安装git\n### 官网下载\n链接：[Git下载官网](https://git-scm.com/downloads)\n双击下载好的exe，选择安装路径即可。\n![Alt text](http://pl06226jn.bkt.clouddn.com/1546493398128.png)\n\n## 安装hexo\n所有必备的应用程序安装完成后，即可使用 npm 安装 Hexo。\n```\n$ npm install -g hexo-cli\n```\n\n### 初始化博客\n在你的本地新建一个存放博客的目录，比如”D:\\MyHexoBlog“，然后在这个目录右键，选择”Git Bash Here“，输入下面两条命令进行初始化：\n```\n$ hexo init\n$ npm install\n```\n初始化完成之后，你的目录结构应该是这样的[关键文件config、source、等存在即可]：\n```\n.\n├── _config.yml\n├── package.json\n├── scaffolds\n├── source\n|   ├── _drafts\n|   └── _posts\n└── themes\n```\n\n### 配置网站\n#### _config.yml\n可以在 _config.yml 中修改大部分的配置。\n##### 网站\n\n|参数|描述|\n|:------------------:|:------------------:|\n|title\t|网站标题|\n|subtitle|\t网站副标题|\n|description\t|网站描述|\n|author|\t您的名字|\n|language|\t网站使用的语言|\n|timezone|\t网站时区。Hexo 默认使用您电脑的时区。时区列表。比如说：America/New_York, Japan, 和 UTC 。|\n\n\n\n其中，description主要用于SEO，告诉搜索引擎一个关于您站点的简单描述，通常建议在其中包含您网站的关键词。author参数用于主题显示文章的作者。\n\n##### 网址\n\n\n|参数|描述|默认值|\n|-----------|\n|url\t|网址\t||\n|root\t|网站根目录\t||\n|permalink\t|文章的 永久链接 格式|\t:year/:month/:day/:title/|\n|permalink_defaults\t|永久链接中各部分的默认值\t||\n> 如果您的网站存放在子目录中，例如 http://yoursite.com/blog，则请将您的 url 设为 http://yoursite.com/blog 并把 root 设为 /blog/。\n\n##### 目录 \n> 刚开始没必要修改这部分内容，需要修改请参考：[hexo手册](https://hexo.io/zh-cn/docs/configuration#%E7%9B%AE%E5%BD%95)\n\n##### 文章\n\n\n|参数\t|描述\t|默认值|\n|---------------|\n|new_post_name\t|新文章的文件名称|\t:title.md|\n|default_layout\t|预设布局\t|post|\n|auto_spacing\t|在中文和英文之间加入空格\t|false|\n|titlecase\t|把标题转换为 title case\t|false|\n|external_link\t|在新标签中打开链接\t|true|\n|filename_case\t|把文件名称转换为 (1) 小写或 (2) 大写|\t0|\n|render_drafts\t|显示草稿\t|false|\n|post_asset_folder|\t启动 Asset 文件夹|\tfalse|\n|relative_link|\t把链接改为与根目录的相对位址\t|false|\n|future|\t显示未来的文章\t|true|\n|highlight\t|代码块的设置\t|\n####  package.json\n\n### 启动服务\n如果没有出错的话，在git命令行中继续执行下面的指令启动服务：\n```\n$ hexo g \n$ hexo s\n```\n启动之后，在浏览器中访问：http://localhost:4000/，博客页面如下：\n![Alt text](http://pl06226jn.bkt.clouddn.com/1546494415746.png)\n很丑而且是本地的，如何能够通过外网访问呢？\n\n## 通过github\n### 创建github仓库\n想要别人也访问到你的页面，首先在Github官网上注册一个账号，有账号的跳过注册，直接登录。登录后找到new repository按钮创建一个新的仓库，填写并创建。\n![Alt text](http://pl06226jn.bkt.clouddn.com/1546494653963.png)\n\n>要注意的是：这个名字的格式必须为**youname**.github.io，这个yourname要与你的github账户名相同，比如我的账户名是paidaxingNUDT.，我的地址就是paidaxingNUDT.github.io\n\n### 配置本地博客文件\n首先打开站点配置文件_config.yml，找到最后的deploy属性，修改为：\n```\ndeploy:\n  type: git\n  repository: git@github.com:paidaxingNUDT/paidaxingNUDT.github.io.git\n  branch: master\n```\n> 注意该配置文件属性后面的冒号必须要有一个空格，否则会报错\n\n 在sorce文件夹下创建CNAME文件：\n ![Alt text](http://pl06226jn.bkt.clouddn.com/1546495555353.png)\n编辑为yourname.github.io ，保存\n\n### 配置Github的SSH\n首先选择账户的setting：\n![Alt text](http://pl06226jn.bkt.clouddn.com/1546495048466.png)\n然后选择SSH并创建一个新的：\n![Alt text](http://pl06226jn.bkt.clouddn.com/1546495115058.png)\n用管理员身份开命令提示符：\n输入以下命令：\n\n```python\nssh-keygen -t rsa -C \"your github name\"\n#三个回车，保存SSH文件在默认地址：我的是(C:\\Users\\Monkey/.ssh/id_rsa)\n#出现Generating public/private rsa key pair.\n#Enter file in which to save the key (C:\\Users\\Monkey/.ssh/id_rsa):\n#查看SSH文件\n\nTYPE C:\\Users\\Monkey\\.ssh\\id_rsa.pub\n\n# ssh-rsa AAAAB3Nz12332456789..................#很长一串即为SSH\n```\n将该SSH复制到下方并创建：\n![Alt text](http://pl06226jn.bkt.clouddn.com/1546495451770.png)\n\n 配置完成之后通过该命令同步：\n```\n$ hexo clean\n$ hexo g\n$ hexo d\n```\n\n没有出错的话，输入yourname.github.io即可访问你的博客主页\n\n如果想要有自己的域名。。。等我填坑吧。。。忙着赶论文，没有啥时间写啦~~\n\n\n## 问题合集\n### 1. Error: Cannot find module 'cheerio'\n在更新我的配置并同步到github上时，输入\n```\nhexo g\n```\n出现该问题。\n\n首先排除我的环境变量设置的问题，在nodejs的安装目录和这个目录下：\n![Alt text](http://pl06226jn.bkt.clouddn.com/1546501315329.png)\n确实不存在cheerio这个模块，通过npm进行安装即可，在你的博客目录下，右键，点击git bush here，输入以下命令：\n\n```\nnpm install cheeio --save\n```\n通过npm安装第三方模块，-save的作用的把你安装的这个第三方模块的依赖写入到package.json里面。\n\n\n\n### 2. hexo d后 ERROR Deployer not found: git\n\n","tags":["monkey"]}]